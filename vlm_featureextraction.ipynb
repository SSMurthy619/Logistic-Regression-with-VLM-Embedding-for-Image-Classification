{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "062d9f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import open_clip\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "269e318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a4a0b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,_, preprocess = open_clip.create_model_and_transforms('ViT-B-16', pretrained='laion2b_s34b_b88k')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e25b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path(r\"E:\\POC_Jain_Irrigation\\data\\images\\train\")\n",
    "fw_test_dir = Path(r\"E:\\POC_Jain_Irrigation\\data\\images\\val\")  # forward test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53e6c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(folder_path, batch_size=16):\n",
    "    dataset = datasets.ImageFolder(folder_path, transform=preprocess)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_embeddings, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in tqdm(loader, desc=f\"Extracting from {folder_path.name}\"):\n",
    "            imgs = imgs.to(device)\n",
    "            feats = model.encode_image(imgs)\n",
    "            feats = feats / feats.norm(dim=-1, keepdim=True)\n",
    "            all_embeddings.append(feats.cpu().numpy())\n",
    "            all_labels.extend(lbls.numpy())\n",
    "\n",
    "    embeddings = np.vstack(all_embeddings)\n",
    "    labels = np.array(all_labels)\n",
    "    class_names = dataset.classes\n",
    "    return embeddings, labels, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc97c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting from train: 100%|███████████████████████████████████████████████████████████| 21/21 [00:15<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings shape: (332, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all, class_names = extract_embeddings(train_dir)\n",
    "print(\"Total embeddings shape:\", X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dba79349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (232, 512) Test: (100, 512)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Split TRAIN into 70:30 train/test ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all,\n",
    "    test_size=0.3,\n",
    "    stratify=y_all,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2a8ce52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting from val: 100%|███████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Test: (97, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_fw, y_fw, _ = extract_embeddings(fw_test_dir)\n",
    "print(\"Forward Test:\", X_fw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbf5bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved embeddings to /embeddings folder\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"embeddings\", exist_ok=True)\n",
    "\n",
    "with open(\"embeddings/clip_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_train, y_train, class_names), f)\n",
    "\n",
    "with open(\"embeddings/clip_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_test, y_test, class_names), f)\n",
    "\n",
    "with open(\"embeddings/clip_forward.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_fw, y_fw, class_names), f)\n",
    "\n",
    "print(\"✅ Saved embeddings to /embeddings folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7d6dfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved embeddings/clip_forward.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example for forward test embeddings\n",
    "df_fw = pd.DataFrame(X_fw)\n",
    "\n",
    "# Add labels (optional)\n",
    "df_fw[\"label\"] = y_fw\n",
    "\n",
    "# Save as CSV\n",
    "df_fw.to_csv(\"embeddings/clip_forward.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved embeddings/clip_forward.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf171fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved embeddings/clip_train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example for forward test embeddings\n",
    "df_train = pd.DataFrame(X_train)\n",
    "\n",
    "# Add labels (optional)\n",
    "df_train[\"label\"] = y_train\n",
    "\n",
    "# Save as CSV\n",
    "df_train.to_csv(\"embeddings/clip_train.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved embeddings/clip_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7de51f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved embeddings/clip_test.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example for forward test embeddings\n",
    "df_test = pd.DataFrame(X_test)\n",
    "\n",
    "# Add labels (optional)\n",
    "df_test[\"label\"] = y_test\n",
    "\n",
    "# Save as CSV\n",
    "df_test.to_csv(\"embeddings/clip_test.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved embeddings/clip_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8c1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
